# LLM4CVD: An Experimental Study

This is the codebase for the paper "Investigating Large Language Models for Code Vulnerability Detection: An Experimental Study".

**Reproduction of Baseline Models**
We provide training codes of three graph-based models, two medium-size BERT-based sequence models, and four Llama LLMs to study their performance for the code vulnerability detection task.  

## Requirements
TBD

## Dataset
TBD

## How to Run and Evaluate
TBD

## Helpful Resources
TBD

## Acknowledgement

We are very grateful that the authors of VulLLM, CodeLlama, and Meta AI which make their codes or models publicly available so that we can carry out this experimental study on top of their hard works.

## Citing this work
Collaboration and pull requests are always welcome! If you have any questions or suggestions, please feel free to contact me : )

```bibtex
@article{jiang2024investigating,
  title={Investigating Large Language Models for Code Vulnerability Detection: An Experimental Study},
  author={Jiang, Xuefeng and Wu, Lvhua and Sun, Sheng and Li, Jia and Xue, Jingjing and Wang, Yuwei and Wu, Tingting and Liu, Min},
  journal={arXiv preprint},
  year={2024}
}


@article{feng2020codebert,
  title={Codebert: A pre-trained model for programming and natural languages},
  author={Feng, Zhangyin and Guo, Daya and Tang, Duyu and Duan, Nan and Feng, Xiaocheng and Gong, Ming and Shou, Linjun and Qin, Bing and Liu, Ting and Jiang, Daxin and others},
  journal={arXiv preprint arXiv:2002.08155},
  year={2020}
}

@article{du2024generalization,
  title={Generalization-Enhanced Code Vulnerability Detection via Multi-Task Instruction Fine-Tuning},
  author={Du, Xiaohu and Wen, Ming and Zhu, Jiahao and Xie, Zifan and Ji, Bin and Liu, Huijun and Shi, Xuanhua and Jin, Hai},
  journal={arXiv preprint arXiv:2406.03718},
  year={2024}
}
```
